{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T09:49:36.991967Z",
     "iopub.status.busy": "2025-11-01T09:49:36.991206Z",
     "iopub.status.idle": "2025-11-01T09:50:00.794811Z",
     "shell.execute_reply": "2025-11-01T09:50:00.794096Z",
     "shell.execute_reply.started": "2025-11-01T09:49:36.991936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: cudf-cu12 25.2.2\n",
      "Uninstalling cudf-cu12-25.2.2:\n",
      "  Successfully uninstalled cudf-cu12-25.2.2\n",
      "Found existing installation: pylibcudf-cu12 25.2.2\n",
      "Uninstalling pylibcudf-cu12-25.2.2:\n",
      "  Successfully uninstalled pylibcudf-cu12-25.2.2\n",
      "Found existing installation: cudf-polars-cu12 25.6.0\n",
      "Uninstalling cudf-polars-cu12-25.6.0:\n",
      "  Successfully uninstalled cudf-polars-cu12-25.6.0\n",
      "Found existing installation: libcugraph-cu12 25.6.0\n",
      "Uninstalling libcugraph-cu12-25.6.0:\n",
      "  Successfully uninstalled libcugraph-cu12-25.6.0\n",
      "Found existing installation: pylibcugraph-cu12 25.6.0\n",
      "Uninstalling pylibcugraph-cu12-25.6.0:\n",
      "  Successfully uninstalled pylibcugraph-cu12-25.6.0\n",
      "Found existing installation: libraft-cu12 25.2.0\n",
      "Uninstalling libraft-cu12-25.2.0:\n",
      "  Successfully uninstalled libraft-cu12-25.2.0\n",
      "Found existing installation: pylibraft-cu12 25.2.0\n",
      "Uninstalling pylibraft-cu12-25.2.0:\n",
      "  Successfully uninstalled pylibraft-cu12-25.2.0\n",
      "Found existing installation: rmm-cu12 25.2.0\n",
      "Uninstalling rmm-cu12-25.2.0:\n",
      "  Successfully uninstalled rmm-cu12-25.2.0\n",
      "Found existing installation: google-cloud-bigquery 3.25.0\n",
      "Uninstalling google-cloud-bigquery-3.25.0:\n",
      "  Successfully uninstalled google-cloud-bigquery-3.25.0\n",
      "\u001b[33mWARNING: Skipping google-cloud-bigquery-storage as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: pandas-gbq 0.29.2\n",
      "Uninstalling pandas-gbq-0.29.2:\n",
      "  Successfully uninstalled pandas-gbq-0.29.2\n",
      "Found existing installation: bigframes 2.12.0\n",
      "Uninstalling bigframes-2.12.0:\n",
      "  Successfully uninstalled bigframes-2.12.0\n",
      "Found existing installation: rich 14.1.0\n",
      "Uninstalling rich-14.1.0:\n",
      "  Successfully uninstalled rich-14.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigquery-magics 0.10.1 requires google-cloud-bigquery<4.0.0,>=3.13.0, which is not installed.\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip uninstall -y cudf-cu12 pylibcudf-cu12 cudf-polars-cu12 libcugraph-cu12 pylibcugraph-cu12 libraft-cu12 pylibraft-cu12 rmm-cu12 google-cloud-bigquery google-cloud-bigquery-storage pandas-gbq bigframes rich\n",
    "\n",
    "!pip install -q pytube pydub openai-whisper keybert sentencepiece torch torchvision torchaudio\n",
    "!pip install -q \"transformers>=4.35.0\" \"pyarrow>=19.0.0,<20.0.0\" \"pydantic<2.12\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T09:50:31.380105Z",
     "iopub.status.busy": "2025-11-01T09:50:31.379312Z",
     "iopub.status.idle": "2025-11-01T09:50:59.646784Z",
     "shell.execute_reply": "2025-11-01T09:50:59.645986Z",
     "shell.execute_reply.started": "2025-11-01T09:50:31.380073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 09:50:41.720780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761990641.886904      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761990641.938000      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "from keybert import KeyBERT\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T09:56:06.399064Z",
     "iopub.status.busy": "2025-11-01T09:56:06.398765Z",
     "iopub.status.idle": "2025-11-01T09:56:07.091920Z",
     "shell.execute_reply": "2025-11-01T09:56:07.091154Z",
     "shell.execute_reply.started": "2025-11-01T09:56:06.399042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pytube 15.0.0\n",
      "Uninstalling pytube-15.0.0:\n",
      "  Successfully uninstalled pytube-15.0.0\n",
      "\u001b[33mWARNING: Skipping pytube3 as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y pytube pytube3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T09:56:25.511240Z",
     "iopub.status.busy": "2025-11-01T09:56:25.510568Z",
     "iopub.status.idle": "2025-11-01T09:56:31.924473Z",
     "shell.execute_reply": "2025-11-01T09:56:31.923718Z",
     "shell.execute_reply.started": "2025-11-01T09:56:25.511196Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pytube (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/pytube/pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T09:58:59.068979Z",
     "iopub.status.busy": "2025-11-01T09:58:59.068424Z",
     "iopub.status.idle": "2025-11-01T09:59:30.585337Z",
     "shell.execute_reply": "2025-11-01T09:59:30.584629Z",
     "shell.execute_reply.started": "2025-11-01T09:58:59.068958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] UWYT7KitauA: nsig extraction failed: Some formats may be missing\n",
      "         n = zuqJ98px2XXRWuCR ; player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] UWYT7KitauA: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] UWYT7KitauA: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Audio downloaded: lecture_audio.mp3                      \n"
     ]
    }
   ],
   "source": [
    "!pip install -q yt_dlp pydub\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import yt_dlp\n",
    "import os\n",
    "\n",
    "def download_audio_ytdlp(url, output_path=\"lecture_audio.mp3\"):\n",
    "    temp_file = \"temp_audio\"\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": f\"{temp_file}.%(ext)s\",\n",
    "        \"quiet\": True,\n",
    "        \"postprocessors\": [{\"key\": \"FFmpegExtractAudio\", \"preferredcodec\": \"mp3\"}]\n",
    "    }\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "\n",
    "        # Find downloaded mp3 file\n",
    "        for file in os.listdir():\n",
    "            if file.startswith(temp_file) and file.endswith(\".mp3\"):\n",
    "                os.rename(file, output_path)\n",
    "                break\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error downloading audio:\", e)\n",
    "        return None\n",
    "\n",
    "# ‚úÖ Example\n",
    "youtube_link = \"https://youtu.be/UWYT7KitauA\"\n",
    "audio_path = download_audio_ytdlp(youtube_link)\n",
    "print(\"‚úÖ Audio downloaded:\", audio_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T10:00:50.455007Z",
     "iopub.status.busy": "2025-11-01T10:00:50.454627Z",
     "iopub.status.idle": "2025-11-01T10:01:10.745417Z",
     "shell.execute_reply": "2025-11-01T10:01:10.744603Z",
     "shell.execute_reply.started": "2025-11-01T10:00:50.454988Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Loading Whisper model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72.1M/72.1M [00:00<00:00, 206MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîä Transcribing audio...\n",
      "\n",
      "‚úÖ Transcription complete!\n",
      "\n",
      "üìù Transcript saved to lecture_transcript.txt\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai-whisper\n",
    "\n",
    "import whisper\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    print(\"üéß Loading Whisper model...\")\n",
    "    model = whisper.load_model(\"tiny\")  \n",
    "    print(\"üîä Transcribing audio...\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    \n",
    "    transcript = result[\"text\"]\n",
    "    print(\"\\n‚úÖ Transcription complete!\\n\")\n",
    "    return transcript\n",
    "\n",
    "# ‚úÖ Example\n",
    "transcript = transcribe_audio(\"lecture_audio.mp3\")\n",
    "\n",
    "with open(\"lecture_transcript.txt\", \"w\") as f:\n",
    "    f.write(transcript)\n",
    "\n",
    "print(\"üìù Transcript saved to lecture_transcript.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T10:05:46.671360Z",
     "iopub.status.busy": "2025-11-01T10:05:46.670463Z",
     "iopub.status.idle": "2025-11-01T10:05:48.739040Z",
     "shell.execute_reply": "2025-11-01T10:05:48.738271Z",
     "shell.execute_reply.started": "2025-11-01T10:05:46.671335Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers sentencepiece torch keybert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T10:03:06.992013Z",
     "iopub.status.busy": "2025-11-01T10:03:06.991724Z",
     "iopub.status.idle": "2025-11-01T10:03:40.498084Z",
     "shell.execute_reply": "2025-11-01T10:03:40.497360Z",
     "shell.execute_reply.started": "2025-11-01T10:03:06.991990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc4792595284dd9bd254ecd5fb18f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f58834ebe794b4ea9e6e84af5b78513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4801571d7f85431d8f758498f8243d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c20db1061b4aee96a3f6eac8376c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599520befba84e6c8dd194681d0d2e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8d2fe6de024c0c9bb0f30e2bf840e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a4425db95d47b488367234b8134c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fd24ce53a84d548cd99c5c0cbbd2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6643233c6f41c1a2be376d29ff4413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf1975ae74147bcb34172112016e368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40a12c93f684f159695f2f5eb3840d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b02fc4d31f4276869f23ce8aef46a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4a794808d84306b5e429a16300ca26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Summarizing lecture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Generating questions...\n",
      "üîç Extracting key topics...\n",
      "\n",
      "‚úÖ Summary:\n",
      " This chapter talks about democracy and how power is shared among the government branches. In this lesson we study the political situations of Belgium and Sri Lanka to understand why Power Sharing is important. We also learn about different ways of power sharing. First, let us see the situation in Belgium. In the capital city Brussels, 80% of people speak French and only 20% speak Dutch. Sri Lanka is an island nation near the southern coast of Tamil Nadu India. Its population is about 2 crore which is similar to Ariana. There are 2 major ethnic groups in Sri Lanka. Sinhala speakers are about 74% the majority and Tamil speakers are 18% which are minority. Sri Lanka became independent in 1948. Sinhala leaders being the majority wanted to dominate the government. In 1956, an act was possibl in 1956 to create a state of emergency. Most Tamil's are Hindus or Muslims. About 7% are Christians from bothSinhala and Tamil groups.  Tamil parties and groups demanded recognition of Tamil as an official language. Regional autonomy for Tamil majority areas and equality of opportunity in education and jobs. These demands were repeatedly denied leading to frustration among Tamil's. By the 1980s, Tamil political organizations began demanding an independent Tamil elam. Means a separate state in the north and east of Sri Lank. Distrust between the Sinhala and Tamil communities turned into a civil war. Thousands of people from both sides were killed. The civil war was finally ended in 2009, but the damages were long lasting. Now let us see what happened in Belgium. Let us see the key features of the Belgian model. Bruzals the capital has a separate government with equal representation for both communities. Special laws require approval from a majority in both language groups. State governments with power. Many powers of the central government were given to state governments. Even though the model is complex, it prevented conflicts and kept the country united. Power sharing stands in unity, while domination by one group creates division. By making mutually acceptable arrangements, Belgium avoided conflict and division. Sri Lanka highlights the dangers of majority dominance, refusing to share power undermind unity, leading to civil war and suffering. By this, we conclude that democracy works best when all communities feel respected. Democracy means sharing power with those who are affected by its decisions. People have a right to be consulted about how they are governed. A legitimate government is one where citizens participate and feel they have a stake in the system. Power is shared among different organs of government that is legislature, executive, judiciary. Political parties share power by competing in elections, forming coalescence or alienates. Pressure groups, example farmers, business groups, influence decisions through participation or lobbying. Belgium successfully divided power among regions, communities and government levels. Whereas Sri Lanka refused power sharing, leading to civil war and instability. The backbone of a good democracy is balance. It creates balance, avoids conflicts and strengthens national unity. Check the description.  is the backbone of  a gooddemocracy. It create balance, avoid conflicts and strengthen national unity, it creates balance and avoids conflicts. check the description to see how it works.\n",
      "\n",
      "‚ùì Quiz Questions:\n",
      " What is the backbone of a good democracy? ?????????????????????????????????????????????????????????????????????????????????????????????????????\n",
      "\n",
      "üß© Key Topics:\n",
      " ['power', 'tamil', 'government', 'about', 'lanka', 'groups', 'belgium', 'sharing', 'majority', 'democracy']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "# ====== LOAD SUMMARIZER MODEL ======\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# ====== LOAD QUESTION GENERATOR ======\n",
    "qg = pipeline(\"text2text-generation\", model=\"iarfmoose/t5-base-question-generator\")\n",
    "\n",
    "# ====== LOAD KEYWORD EXTRACTOR (using regex fallback) ======\n",
    "def extract_keywords(text, n=10):\n",
    "    words = re.findall(r'\\b[A-Za-z]{5,}\\b', text)\n",
    "    freq = {}\n",
    "    for w in words:\n",
    "        freq[w.lower()] = freq.get(w.lower(), 0) + 1\n",
    "    sorted_words = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [w for w, _ in sorted_words[:n]]\n",
    "\n",
    "# ====== MAIN FUNCTION ======\n",
    "def analyze_lecture(transcript, chunk_size=1000):\n",
    "    print(\"üìñ Summarizing lecture...\")\n",
    "    chunks = [transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size)]\n",
    "    summaries = [summarizer(chunk, max_length=150, min_length=60, do_sample=False)[0]['summary_text']\n",
    "                 for chunk in chunks]\n",
    "    full_summary = \" \".join(summaries)\n",
    "\n",
    "    print(\"üß† Generating questions...\")\n",
    "    q_output = qg(full_summary + \" generate 5 questions about this text\")[0]['generated_text']\n",
    "\n",
    "    print(\"üîç Extracting key topics...\")\n",
    "    keywords = extract_keywords(full_summary)\n",
    "\n",
    "    return full_summary, q_output, keywords\n",
    "\n",
    "# ====== RUN PIPELINE ======\n",
    "with open(\"lecture_transcript.txt\") as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "summary, questions, keywords = analyze_lecture(transcript)\n",
    "\n",
    "print(\"\\n‚úÖ Summary:\\n\", summary)\n",
    "print(\"\\n‚ùì Quiz Questions:\\n\", questions)\n",
    "print(\"\\nüß© Key Topics:\\n\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T10:09:49.712125Z",
     "iopub.status.busy": "2025-11-01T10:09:49.711830Z",
     "iopub.status.idle": "2025-11-01T10:12:00.007805Z",
     "shell.execute_reply": "2025-11-01T10:12:00.007159Z",
     "shell.execute_reply.started": "2025-11-01T10:09:49.712104Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9c7e57888745cfa267e4363fa4ccbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df325350a124e8984ea873a82d71ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffaf8d994254e34b5fdb599372c3986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff49a141cf864f93b8eaa72af0569c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7570de8405a4ea18369a43811659fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee59edf8a3bd4088b3bd164ea15a0783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Lecture Summary Modes:\n",
      "1Ô∏è‚É£ Short  2Ô∏è‚É£ Medium  3Ô∏è‚É£ Detailed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Choose summary length (1/2/3):  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 80, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Summary:\n",
      " This chapter talks about democracy and how power is shared among the government branches. We study the political situations of Belgium and Sri Lanka to understand why Power Sharing is important. We also learn about different ways of power sharing. Sri Lanka is an island nation near the southern coast of Tamil Nadu India. Its population is about 2 crore which is similar to Ariana. There are 2 major ethnic groups in Sri Lanka. Sinhala speakers, Tamil speakers. Sri Lanka became independent in 1948. Sinhala leaders being the majority wanted to dominate the government. In 1956, an act was possibl in 1956 to create a state of emergency. Sri Lanka and Tamil's felt elinated because these policies disregard their language and culture. Preferential policies were introduced to favour Sinhala applicants for university admissions and government jobs. Tamil parties and groups demanded recognition of Tamil as an official language. Distrust between the Sinhala and Tamil communities turned into a civil war. Thousands of people from both sides were killed. The civil war was finally ended in 2009, but the damages were long lasting. Bruzals the capital has a separate government with equal representation for both communities. Many powers of the central government were given to state governments. Bruzals became the headquarters of the European Union. Power sharing stands in unity, while domination by one group creates division. By making mutually acceptable arrangements, Belgium avoided conflict and division. Sri Lanka highlights the dangers of majority dominance, refusing to share power undermind unity. Democracy means sharing power with those who are affected by its decisions. People have a right to be consulted about how they are governed. A legitimate government is one where citizens participate. Political parties share power by competing in elections, forming coalescence or alienates. Pressure groups influence decisions through participation or lobbying. This ensures power is not concentrated in one party or group. A good democracy is the backbone of a good democracy. It creates balance, avoids conflicts and strengthens national unity. Check the description of a democracy.\n",
      "\n",
      "üß© Keywords: lanka, tamil, sri, sinhala, nadu, india, governments, government\n",
      "\n",
      "üí¨ Ask anything about this lecture! (type 'exit' to stop)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì You:  tell about bruzals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI: Bruzals became the headquarters of the European Union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì You:  more about sinhala\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI: Sri Lanka\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì You:  who were killed \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI: Thousands of people from both sides\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì You:  which both\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI: Belgium and Sri Lanka\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Ending session.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from keybert import KeyBERT\n",
    "import re\n",
    "\n",
    "# Load models\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# Auto-length summarizer\n",
    "def summarize_text(text, mode=\"short\"):\n",
    "    length = len(text.split())\n",
    "    if length < 50:\n",
    "        return text\n",
    "    if mode == \"short\":\n",
    "        max_len, min_len = 80, 30\n",
    "    elif mode == \"medium\":\n",
    "        max_len, min_len = 150, 60\n",
    "    else:\n",
    "        max_len, min_len = 250, 100\n",
    "\n",
    "    chunks = [text[i:i+1000] for i in range(0, len(text), 1000)]\n",
    "    summaries = summarizer(chunks, max_length=max_len, min_length=min_len, do_sample=False)\n",
    "    return \" \".join([s[\"summary_text\"] for s in summaries])\n",
    "\n",
    "# Keyword extractor\n",
    "def extract_keywords(text, n=8):\n",
    "    try:\n",
    "        return [kw for kw, _ in kw_model.extract_keywords(text, top_n=n)]\n",
    "    except:\n",
    "        words = re.findall(r'\\b[A-Za-z]{5,}\\b', text)\n",
    "        freq = {}\n",
    "        for w in words:\n",
    "            freq[w.lower()] = freq.get(w.lower(), 0) + 1\n",
    "        return [w for w, _ in sorted(freq.items(), key=lambda x: x[1], reverse=True)[:n]]\n",
    "\n",
    "# Interactive mode\n",
    "def interactive_summary(transcript):\n",
    "    print(\"üéß Lecture Summary Modes:\")\n",
    "    print(\"1Ô∏è‚É£ Short  2Ô∏è‚É£ Medium  3Ô∏è‚É£ Detailed\")\n",
    "    mode = {\"1\": \"short\", \"2\": \"medium\", \"3\": \"long\"}.get(input(\"üëâ Choose summary length (1/2/3): \").strip(), \"short\")\n",
    "\n",
    "    summary = summarize_text(transcript, mode)\n",
    "    print(\"\\nüìÑ Summary:\\n\", summary)\n",
    "\n",
    "    keywords = extract_keywords(summary)\n",
    "    print(\"\\nüß© Keywords:\", \", \".join(keywords))\n",
    "\n",
    "    print(\"\\nüí¨ Ask anything about this lecture! (type 'exit' to stop)\")\n",
    "    while True:\n",
    "        q = input(\"‚ùì You: \")\n",
    "        if q.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"üëã Ending session.\")\n",
    "            break\n",
    "        ans = qa(question=q, context=summary)\n",
    "        print(\"ü§ñ AI:\", ans[\"answer\"])\n",
    "\n",
    "# Run\n",
    "with open(\"lecture_transcript.txt\") as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "interactive_summary(transcript)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
